{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATATHON PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributer: Jinran Jin, Peng Zhao, Melissa Tam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing data analysis, the size of the data we use is crucial to the overall accuracy of the models. There are lots of method to augment the data we train. For example, bootstraping. This is a way to create multiple samples from the origianl dataset. But the data we got form bootsraping are still from the real dataset. However, there are drawbacks related to this method. If we have a relatively small dataset, this might not be helpful. This could also lead to underestimation of variablity. Here we are presenting a whole new way of bootstraping, using GAN to generate \"fake\" data based on training data. Therefore we can hopfully capture the hidden feature behind the \"real data\" and ultimately increase the robustness of the training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion and SVM for Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')['quality'].values\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')['quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=16, max_iter=6000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', probability=True))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = clf.predict(X_test)\n",
    "y_test_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_predict), annot=True)\n",
    "print('accuracy:', accuracy_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wineDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx]\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "size = train.shape[0]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train_scale = scaler.transform(train)\n",
    "\n",
    "train_dataloader = DataLoader(wineDataset(train_scale), batch_size=size, shuffle=True)\n",
    "next(enumerate(train_dataloader))[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_len = 100\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(noise_len, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 12),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.gen(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.dis(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "real_label = torch.ones((size, 1), dtype=torch.float32, device=device)\n",
    "fake_label = torch.zeros((size, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        \n",
    "        # real data\n",
    "        netD.zero_grad()\n",
    "        data = data.to(torch.float32).to(device)\n",
    "        \n",
    "        output = netD(data)\n",
    "\n",
    "        errD_real = criterion(output, real_label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # fake data\n",
    "        noise = torch.randn(size, noise_len, device=device)\n",
    "        fake = netG(noise)\n",
    "        \n",
    "        output = netD(fake)\n",
    "\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        print('[%d/%d]\\tLoss_D: %.4f\\tReal mean: %.4f\\tFake mean: %.4f' % (epoch, num_epoch, errD.item(), D_x, D_G_z1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(size, noise_len, device=device)\n",
    "        fake = netG(noise)\n",
    "        output = netD(fake)\n",
    "        \n",
    "        errG = criterion(output, real_label)\n",
    "        errG.backward()\n",
    "        \n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        G_losses.append(errG.item())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print('[%d/%d]\\tLoss_G: %.4f\\tFake mean: %.4f' % (epoch, num_epoch, errG.item(), D_G_z2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the trained model and generating the fake data\n",
    "netD = Discriminator()\n",
    "netD.load_state_dict(torch.load('./model/netD.pt'))\n",
    "\n",
    "netG = Generator()\n",
    "netG.load_state_dict(torch.load('./model/netG.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating 3000 data with GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(3000, noise_len, device=device)\n",
    "    fake = netG(noise).cpu()\n",
    "    fake = scaler.inverse_transform(fake)\n",
    "\n",
    "fake = pd.DataFrame(fake).round(3)\n",
    "fake.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake = fake.iloc[:, 0:11]\n",
    "y_fake = fake.iloc[:, 11].round().clip(3, 8)\n",
    "X_aug = np.concatenate((X_fake.values, X_train.values))\n",
    "y_aug = np.concatenate((y_fake, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting model with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', probability=True))\n",
    "clf.fit(X_aug, y_aug)\n",
    "\n",
    "logreg = make_pipeline(StandardScaler(), LogisticRegression(random_state=16, max_iter=6000))\n",
    "logreg.fit(X_aug, y_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = clf.predict(X_test)\n",
    "y_test_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "y_test_predict_log = logreg.predict(X_test)\n",
    "y_test_pred_prob_log = logreg.predict_proba(X_test)\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_predict), annot=True)\n",
    "\n",
    "print('auc svm:', roc_auc_score(y_test, y_test_pred_prob, multi_class='ovr'))\n",
    "print('accuracy svm:', accuracy_score(y_test, y_test_predict))\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_predict_log), annot=True)\n",
    "\n",
    "print('log auc:', roc_auc_score(y_test, y_test_pred_prob_log, multi_class='ovr'))\n",
    "print('log accuracy:', accuracy_score(y_test, y_test_predict_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, we got a higher accuracy for SVM from our augmented data. For the logistic regression, the accuracy slightly dropped by 0.02. This might because our generated data was not accurate and can not be representitive for the entire population. It might also becasue the formula for logistic regression is different to SVM which can results in different result. \n",
    "\n",
    "For SVM our 3000 generated data was indeed helpful for the accuracy. Which is a better solution to the lacking data proble compared to the traditional bootstraping. However, the improvement was not significant enough to say that our method is better than using the orignal dataset. By using different model Architecture or trying out different training method might lead to a better result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, in this work, we demonstrated a new way of data augmentation for traditional statistical models like logistic regression and SVM. By doing so we provide a new direction of further studies to find a better deep learning model like GAN to generate better data for bootstrapping. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
